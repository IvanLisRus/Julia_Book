{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\"><img src=\"https://www.juliabox.org/assets/img/juliacloudlogo.png\" style=\"margin: 0px 0px 0px 0px; padding-right: 20px;width: 80px; float: left;\" title=\"\" alt=\"\" /></div>\n",
    "<img src=\"http://dmkpress.com/images/cms/thumbs/a5b0aeaa3fa7d6e58d75710c18673bd7ec6d5f6d/978-5-97060-370-3_270_369__100.jpg\" style=\"margin: 0px 0px 5px 20px; width: 100px; float: right;\" title=\"\" alt=\"\" />\n",
    "Всестороннее введение в новый язык программирования для научно-технических вычислений [Julia](http://julialang.org/) в книге Малколма Шеррингтона, Packt Publishing, июль 2015.\n",
    "\n",
    "<h1>Осваиваем язык Julia</h1><br />\n",
    "\n",
    "Совершенствование мастерства в области аналитики и программирования при помощи Julia в целях решения задач комплексной обработки данных\n",
    "<div style=\"text-align: left;font-size:8pt;padding-top:10px;\">Программный код Julia (v0.4.5) протестирован в Windows 8.1/10 и Linux/Lubuntu 16.4</div>\n",
    "<div style=\"text-align: left;\"><h1>Глава 6. Научное программирование</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимизационные задачи\n",
    "## Пакет JuMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JuMP\n",
    "\n",
    "m = Model()\n",
    "\n",
    "@variable(m, 0 <= x <= 5 );\n",
    "@variable(m, 0 <= y <= 10 );\n",
    "@objective(m, Max, 5x + 3y );\n",
    "@constraint(m, 2x + 5y <= 7.0 ); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":Optimal"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status = solve(m) # => :Optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение функции 17.50 в (3.50,0.00)\n"
     ]
    }
   ],
   "source": [
    "@printf \"Значение функции %5.2f в (%4.2f,%4.2f)\\n\" getobjectivevalue(m) getvalue(x) getvalue(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение целевой функции: 16.0x[1] = 1.0, p[1]/w[1] = 2.5\n",
      "x[2] = 0.0, p[2]/w[2] = 0.375\n",
      "x[3] = 0.0, p[3]/w[3] = 0.5\n",
      "x[4] = 1.0, p[4]/w[4] = 3.5\n",
      "x[5] = 1.0, p[5]/w[5] = 0.8\n",
      "x[6] = 0.0, p[6]/w[6] = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# knapsack.jl\n",
    "#\n",
    "# Решение задачи о ранце\n",
    "\n",
    "using JuMP     # требует установки пакета с решателем задач Cbc, MIB...\n",
    "\n",
    "N = 6;\n",
    "\n",
    "m = Model();                      # Использовать решатель по умолчанию\n",
    "@variable(m, x[1:N], Bin);        # Определить переменную массива для результатов\n",
    "profit = [ 5, 3, 2, 7, 4, 4 ];    # Массив стоимостей размера N\n",
    "weight = [ 2, 8, 4, 2, 5, 6 ];    # Вектор весов такого же размера\n",
    "\n",
    "capacity = 12;\n",
    "\n",
    "@objective(m, Max, dot(profit, x));\n",
    "@constraint(m, dot(weight, x) <= capacity);\n",
    "\n",
    "status = solve(m);               # Решить задачу с помощью решателя MIP \n",
    "@printf \"Значение целевой функции: %.1f\" getobjectivevalue(m);\n",
    "\n",
    "for i = 1:N\n",
    "  print(\"x[$i] = \", getvalue(x[i]));\n",
    "  println(\", p[$i]/w[$i] = \", profit[i]/weight[i]);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пакет Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [1.000005438687492,1.0000079372595394]\n",
       " * Minimum: 0.000000\n",
       " * Iterations: 60\n",
       " * Convergence: true\n",
       "   * |x - x'| < NaN: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-08: true\n",
       "   * |g(x)| < NaN: false\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Function Calls: 115\n",
       " * Gradient Calls: 0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rb(x::Vector)\n",
    "  (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2;\n",
    "end\n",
    "\n",
    "using Optim\n",
    "\n",
    "opt1 = Optim.optimize(rb, [0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Array{Symbol,1}:\n",
       " :method             \n",
       " :initial_x          \n",
       " :minimum            \n",
       " :f_minimum          \n",
       " :iterations         \n",
       " :iteration_converged\n",
       " :x_converged        \n",
       " :xtol               \n",
       " :f_converged        \n",
       " :ftol               \n",
       " :gr_converged       \n",
       " :grtol              \n",
       " :trace              \n",
       " :f_calls            \n",
       " :g_calls            "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames(opt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rb_hess (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rb_grad(x::Vector, sv::Vector)\n",
    "  sv[1] = -2.0*(1.0 - x[1]) - 400.0*(x[2] - x[1]^2) * x[1];\n",
    "  sv[2] = 200.0*(x[2] - x[1]^2);\n",
    "end\n",
    "\n",
    "function rb_hess(x::Vector, sm::Matrix)\n",
    "  sm[1, 1] = 2.0 - 400.0*x[2] + 1200.0*x[1]^2;\n",
    "  sm[1, 2] = -400.0*x[1];\n",
    "  sm[2, 1] = -400.0*x[1];\n",
    "  sm[2, 2] = 200.0;\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.000000e+00     2.000000e+00\n",
      "     1     8.431140e-01     1.588830e+00\n",
      "     2     6.586412e-01     4.959487e+00\n",
      "     3     4.111928e-01     4.096544e+00\n",
      "     4     2.372848e-01     3.547999e+00\n",
      "     5     1.170459e-01     2.534125e+00\n",
      "     6     5.310541e-02     3.644714e+00\n",
      "     7     1.200383e-02     1.126834e-01\n",
      "     8     7.971352e-03     1.736505e-01\n",
      "     9     2.473547e-03     8.315709e-01\n",
      "    10     7.438989e-05     2.854073e-01\n",
      "    11     1.978774e-07     1.286206e-02\n",
      "    12     3.784204e-13     2.087334e-05\n",
      "    13     5.639268e-24     5.214740e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Newton's Method\n",
       " * Starting Point: [0.0,0.0]\n",
       " * Minimizer: [0.9999999999979515,0.9999999999960232]\n",
       " * Minimum: 0.000000\n",
       " * Iterations: 13\n",
       " * Convergence: true\n",
       "   * |x - x'| < 1.0e-32: false\n",
       "   * |f(x) - f(x')| / |f(x)| < 1.0e-08: false\n",
       "   * |g(x)| < 1.0e-08: true\n",
       "   * Reached Maximum Number of Iterations: false\n",
       " * Objective Function Calls: 54\n",
       " * Gradient Calls: 54"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Optim.optimize(rb, rb_grad, rb_hess, [0.0,0.0], method=Optim.Newton(), show_trace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотека NLopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mycons (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NLopt\n",
    "\n",
    "count = 0;\n",
    "\n",
    "function myfunc(x::Vector, grad::Vector)\n",
    "  if length(grad) > 0\n",
    "    grad[1] = 0\n",
    "    grad[2] = 0.5/sqrt(x[2])\n",
    "  end\n",
    "  global count;\n",
    "  count::Int += 1;\n",
    "  sqrt(x[2]);\n",
    "end\n",
    "\n",
    "function mycons(x::Vector, grad::Vector, a, b)\n",
    "  if length(grad) > 0\n",
    "    grad[1] = 3*a * (a*x[1] + b)^2\n",
    "    grad[2] = -1\n",
    "  end\n",
    "  (a*x[1] + b)^3 - x[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = Opt(:LD_MMA, 2);\n",
    "lower_bounds!(opt, [-Inf, 0.]);\n",
    "xtol_rel!(opt,1e-4);\n",
    "min_objective!(opt, myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inequality_constraint!(opt, (x,g) -> mycons(x,g,2,0), 1e-8);\n",
    "inequality_constraint!(opt, (x,g) -> mycons(x,g,-1,1), 1e-8); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ =>  0.544 в ( 0.333, 0.296)"
     ]
    }
   ],
   "source": [
    "(minf,minx,ret) = NLopt.optimize(opt, [1.2, 5.6]);\n",
    "\n",
    "@printf \"Ответ => %6.3f в (%6.3f,%6.3f)\" minf minx[1] minx[2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование с интерфейсом MathProgBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ => 0.5443 в (0.333,0.296)\n"
     ]
    }
   ],
   "source": [
    "using JuMP\n",
    "using NLopt\n",
    "\n",
    "m = Model(solver=NLoptSolver(algorithm=:LD_MMA));\n",
    "\n",
    "a1 = 2; b1 = 0;\n",
    "a2 = -1; b2 = 1;\n",
    "\n",
    "@variable(m, x1);\n",
    "@variable(m, x2 >= 0);\n",
    "@setNLObjective(m, Min, sqrt(x2));\n",
    "@addNLConstraint(m, x2 >= (a1*x1+b1)^3);\n",
    "@addNLConstraint(m, x2 >= (a2*x1+b2)^3);\n",
    "\n",
    "setValue(x1, 1.2);\n",
    "setValue(x2, 5.6);\n",
    "status = solve(m);\n",
    "\n",
    "@printf \"Ответ => %6.4f в (%5.3f,%5.3f)\\n\" getObjectiveValue(m) getvalue(x1) getvalue(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.5",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
